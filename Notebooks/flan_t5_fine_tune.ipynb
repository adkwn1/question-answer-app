{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure options\n",
    "pd.set_option('max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('csv', data_files='datasets/final_sample_small.csv')\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\", max_new_tokens=512)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc7f19cf94d490297dbb52f084d3c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766c8c70718d45d58654acd00b673d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_prefix = \"answer the question: \"\n",
    "\n",
    "# Define our preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    # The \"inputs\" are the tokenized answer:\n",
    "    inputs = [task_prefix + doc for doc in examples[\"Title\"]]\n",
    "    model_inputs = tokenizer(inputs, truncation=True)\n",
    "    \n",
    "    # The \"labels\" are the tokenized outputs:\n",
    "    labels = tokenizer(text_target=examples['Response'], truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\", quiet=True)\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # decode preds and labels\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './t5-flan-py-stackoverflow'\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Set up trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adkwo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895dad267b7c48f4a3048a8614378dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0436, 'learning_rate': 0.0002666666666666666, 'epoch': 0.33}\n",
      "{'loss': 2.8788, 'learning_rate': 0.0002333333333333333, 'epoch': 0.67}\n",
      "{'loss': 2.8256, 'learning_rate': 0.00019999999999999998, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d134e47733340a0843720152e58da89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.595390558242798, 'eval_rouge1': 0.10496883042212396, 'eval_rouge2': 0.019267080537174096, 'eval_rougeL': 0.0869708647836025, 'eval_rougeLsum': 0.09461379494286501, 'eval_runtime': 934.7972, 'eval_samples_per_second': 3.209, 'eval_steps_per_second': 0.802, 'epoch': 1.0}\n",
      "{'loss': 2.6621, 'learning_rate': 0.00016666666666666666, 'epoch': 1.33}\n",
      "{'loss': 2.6405, 'learning_rate': 0.0001333333333333333, 'epoch': 1.67}\n",
      "{'loss': 2.626, 'learning_rate': 9.999999999999999e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814f5eac2e1d48408d86e6eb9b006ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.517094135284424, 'eval_rouge1': 0.11528531964657868, 'eval_rouge2': 0.021652437832587385, 'eval_rougeL': 0.09296964514257781, 'eval_rougeLsum': 0.10229390838740146, 'eval_runtime': 920.5193, 'eval_samples_per_second': 3.259, 'eval_steps_per_second': 0.815, 'epoch': 2.0}\n",
      "{'loss': 2.5324, 'learning_rate': 6.666666666666666e-05, 'epoch': 2.33}\n",
      "{'loss': 2.5157, 'learning_rate': 3.333333333333333e-05, 'epoch': 2.67}\n",
      "{'loss': 2.5048, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2468c4626ca6492a84cd9c32492a786b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4948184490203857, 'eval_rouge1': 0.11578223991082395, 'eval_rouge2': 0.02164258992028923, 'eval_rougeL': 0.09304653141685382, 'eval_rougeLsum': 0.10283131075013124, 'eval_runtime': 1336.0293, 'eval_samples_per_second': 2.245, 'eval_steps_per_second': 0.561, 'epoch': 3.0}\n",
      "{'train_runtime': 34371.7603, 'train_samples_per_second': 1.047, 'train_steps_per_second': 0.131, 'train_loss': 2.6921787109375, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4500, training_loss=2.6921787109375, metrics={'train_runtime': 34371.7603, 'train_samples_per_second': 1.047, 'train_steps_per_second': 0.131, 'train_loss': 2.6921787109375, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a34628d866b44f3a9ace64de0221808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "Looks like you do not have git installed, please install.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\adkwo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\repository.py:569\u001b[0m, in \u001b[0;36mRepository.check_git_versions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 569\u001b[0m     git_version \u001b[39m=\u001b[39m run_subprocess(\u001b[39m\"\u001b[39;49m\u001b[39mgit --version\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocal_dir)\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m    570\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\adkwo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_subprocess.py:83\u001b[0m, in \u001b[0;36mrun_subprocess\u001b[1;34m(command, folder, check, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m     folder \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(folder)\n\u001b[1;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m subprocess\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m     84\u001b[0m     command,\n\u001b[0;32m     85\u001b[0m     stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[0;32m     86\u001b[0m     stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[0;32m     87\u001b[0m     check\u001b[39m=\u001b[39;49mcheck,\n\u001b[0;32m     88\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     89\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mreplace\u001b[39;49m\u001b[39m\"\u001b[39;49m,  \u001b[39m# if not utf-8, replace char by ï¿½\u001b[39;49;00m\n\u001b[0;32m     90\u001b[0m     cwd\u001b[39m=\u001b[39;49mfolder \u001b[39mor\u001b[39;49;00m os\u001b[39m.\u001b[39;49mgetcwd(),\n\u001b[0;32m     91\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m     92\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\adkwo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\adkwo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1024\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1021\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m   1022\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m-> 1024\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1025\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1026\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1027\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1028\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1029\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1030\u001b[0m                         restore_signals,\n\u001b[0;32m   1031\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1032\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1033\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m   1034\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adkwo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1493\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1492\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1493\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1494\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1495\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1496\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1497\u001b[0m                              creationflags,\n\u001b[0;32m   1498\u001b[0m                              env,\n\u001b[0;32m   1499\u001b[0m                              cwd,\n\u001b[0;32m   1500\u001b[0m                              startupinfo)\n\u001b[0;32m   1501\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1502\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1506\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\adkwo\\Documents\\Projects\\Externship\\Dataspeak\\t5_fine_tune.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adkwo/Documents/Projects/Externship/Dataspeak/t5_fine_tune.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m \u001b[39mimport\u001b[39;00m notebook_login\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adkwo/Documents/Projects/Externship/Dataspeak/t5_fine_tune.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m notebook_login()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adkwo/Documents/Projects/Externship/Dataspeak/t5_fine_tune.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mpush_to_hub()\n",
      "File \u001b[1;32mc:\\Users\\adkwo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3676\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[1;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[0;32m   3673\u001b[0m \u001b[39m# If a user calls manually `push_to_hub` with `self.args.push_to_hub = False`, we try to create the repo but\u001b[39;00m\n\u001b[0;32m   3674\u001b[0m \u001b[39m# it might fail.\u001b[39;00m\n\u001b[0;32m   3675\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrepo\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 3676\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_git_repo()\n\u001b[0;32m   3678\u001b[0m model_name \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   3679\u001b[0m \u001b[39mif\u001b[39;00m model_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[1;32mc:\\Users\\adkwo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3534\u001b[0m, in \u001b[0;36mTrainer.init_git_repo\u001b[1;34m(self, at_init)\u001b[0m\n\u001b[0;32m   3532\u001b[0m create_repo(repo_name, token\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_token, private\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_private_repo, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   3533\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepo \u001b[39m=\u001b[39m Repository(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49moutput_dir, clone_from\u001b[39m=\u001b[39;49mrepo_name, token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mhub_token)\n\u001b[0;32m   3535\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[0;32m   3536\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39moverwrite_output_dir \u001b[39mand\u001b[39;00m at_init:\n\u001b[0;32m   3537\u001b[0m         \u001b[39m# Try again after wiping output_dir\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adkwo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:120\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    118\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\adkwo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\repository.py:504\u001b[0m, in \u001b[0;36mRepository.__init__\u001b[1;34m(self, local_dir, clone_from, repo_type, token, git_user, git_email, revision, skip_lfs_files, client)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip_lfs_files \u001b[39m=\u001b[39m skip_lfs_files\n\u001b[0;32m    502\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient \u001b[39m=\u001b[39m client \u001b[39mif\u001b[39;00m client \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m HfApi()\n\u001b[1;32m--> 504\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_git_versions()\n\u001b[0;32m    506\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(token, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    507\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhuggingface_token: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m token\n",
      "File \u001b[1;32mc:\\Users\\adkwo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\repository.py:571\u001b[0m, in \u001b[0;36mRepository.check_git_versions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    569\u001b[0m     git_version \u001b[39m=\u001b[39m run_subprocess(\u001b[39m\"\u001b[39m\u001b[39mgit --version\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_dir)\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m    570\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m--> 571\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLooks like you do not have git installed, please install.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    573\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    574\u001b[0m     lfs_version \u001b[39m=\u001b[39m run_subprocess(\u001b[39m\"\u001b[39m\u001b[39mgit-lfs --version\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_dir)\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mstrip()\n",
      "\u001b[1;31mOSError\u001b[0m: Looks like you do not have git installed, please install."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
